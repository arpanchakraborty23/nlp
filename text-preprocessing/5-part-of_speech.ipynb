{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent=\"Taj Mahal is a beautiful Monument\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corps='Topic sentences are similar to mini thesis statements. Like a thesis statement, a topic sentence has a specific main point. Whereas the thesis is the main point of the essay, the topic sentence is the main point of the paragraph. Like the thesis statement, a topic sentence has a unifying function. But a thesis statement or topic sentence alone doesn’t guarantee unity. An essay is unified if all the paragraphs relate to the thesis, whereas a paragraph is unified if all the sentences relate to the topic sentence. Note: Not all paragraphs need topic sentences. In particular, opening and closing paragraphs, which serve different functions from body paragraphs, generally don’t have topic sentences.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')\n",
    "sent=nltk.sent_tokenize(corps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Topic sentences are similar to mini thesis statements.',\n",
       " 'Like a thesis statement, a topic sentence has a specific main point.',\n",
       " 'Whereas the thesis is the main point of the essay, the topic sentence is the main point of the paragraph.',\n",
       " 'Like the thesis statement, a topic sentence has a unifying function.',\n",
       " 'But a thesis statement or topic sentence alone doesn’t guarantee unity.',\n",
       " 'An essay is unified if all the paragraphs relate to the thesis, whereas a paragraph is unified if all the sentences relate to the topic sentence.',\n",
       " 'Note: Not all paragraphs need topic sentences.',\n",
       " 'In particular, opening and closing paragraphs, which serve different functions from body paragraphs, generally don’t have topic sentences.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\www58\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Topic', 'sentences', 'are', 'similar', 'to', 'mini', 'thesis', 'statements', '.']\n",
      "['Like', 'a', 'thesis', 'statement', ',', 'a', 'topic', 'sentence', 'has', 'a', 'specific', 'main', 'point', '.']\n",
      "['Whereas', 'the', 'thesis', 'is', 'the', 'main', 'point', 'of', 'the', 'essay', ',', 'the', 'topic', 'sentence', 'is', 'the', 'main', 'point', 'of', 'the', 'paragraph', '.']\n",
      "['Like', 'the', 'thesis', 'statement', ',', 'a', 'topic', 'sentence', 'has', 'a', 'unifying', 'function', '.']\n",
      "['But', 'a', 'thesis', 'statement', 'or', 'topic', 'sentence', 'alone', 'doesn', '’', 't', 'guarantee', 'unity', '.']\n",
      "['An', 'essay', 'is', 'unified', 'if', 'all', 'the', 'paragraphs', 'relate', 'to', 'the', 'thesis', ',', 'whereas', 'a', 'paragraph', 'is', 'unified', 'if', 'all', 'the', 'sentences', 'relate', 'to', 'the', 'topic', 'sentence', '.']\n",
      "['Note', ':', 'Not', 'all', 'paragraphs', 'need', 'topic', 'sentences', '.']\n",
      "['In', 'particular', ',', 'opening', 'and', 'closing', 'paragraphs', ',', 'which', 'serve', 'different', 'functions', 'from', 'body', 'paragraphs', ',', 'generally', 'don', '’', 't', 'have', 'topic', 'sentences', '.']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(sent)):\n",
    "    words=nltk.word_tokenize(sent[i])\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Topic', 'NNP'), ('sentences', 'NNS'), ('similar', 'JJ'), ('mini', 'NNS'), ('thesis', 'NN'), ('statements', 'NNS'), ('.', '.')]\n",
      "[('Like', 'IN'), ('thesis', 'NN'), ('statement', 'NN'), (',', ','), ('topic', 'NN'), ('sentence', 'NN'), ('specific', 'JJ'), ('main', 'JJ'), ('point', 'NN'), ('.', '.')]\n",
      "[('Whereas', 'NNP'), ('thesis', 'NN'), ('main', 'JJ'), ('point', 'NN'), ('essay', 'NN'), (',', ','), ('topic', 'JJ'), ('sentence', 'NN'), ('main', 'JJ'), ('point', 'NN'), ('paragraph', 'NN'), ('.', '.')]\n",
      "[('Like', 'IN'), ('thesis', 'NN'), ('statement', 'NN'), (',', ','), ('topic', 'JJ'), ('sentence', 'NN'), ('unifying', 'JJ'), ('function', 'NN'), ('.', '.')]\n",
      "[('But', 'CC'), ('thesis', 'NN'), ('statement', 'NN'), ('topic', 'NN'), ('sentence', 'NN'), ('alone', 'RB'), ('’', 'NNP'), ('guarantee', 'NN'), ('unity', 'NN'), ('.', '.')]\n",
      "[('An', 'DT'), ('essay', 'NN'), ('unified', 'VBD'), ('paragraphs', 'JJ'), ('relate', 'NN'), ('thesis', 'NN'), (',', ','), ('whereas', 'WP'), ('paragraph', 'NN'), ('unified', 'VBD'), ('sentences', 'NNS'), ('relate', 'VBP'), ('topic', 'JJ'), ('sentence', 'NN'), ('.', '.')]\n",
      "[('Note', 'NN'), (':', ':'), ('Not', 'RB'), ('paragraphs', 'VB'), ('need', 'MD'), ('topic', 'VB'), ('sentences', 'NNS'), ('.', '.')]\n",
      "[('In', 'IN'), ('particular', 'JJ'), (',', ','), ('opening', 'VBG'), ('closing', 'NN'), ('paragraphs', 'NN'), (',', ','), ('serve', 'VB'), ('different', 'JJ'), ('functions', 'NNS'), ('body', 'NN'), ('paragraphs', 'NN'), (',', ','), ('generally', 'RB'), ('’', 'JJ'), ('topic', 'NN'), ('sentences', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(sent)):\n",
    "    words=nltk.word_tokenize(sent[i])\n",
    "    words=[word for word in words if word not in set(stopwords.words('english'))]\n",
    "    tag=nltk.pos_tag(words)\n",
    "    print(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
